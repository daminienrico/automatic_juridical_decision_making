{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 4\n",
    "\n",
    "The applied preprocessing is the simple one. \n",
    "The Dataset we are taking into account is composed by: violations + train+ test20-except N-th article.\n",
    "The Doc2Vec is trained on dataset described above and it is tested on the N-th article of the test20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import re\n",
    "import regex\n",
    "import string\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import KFold\n",
    "from gensim import models\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn import svm, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.preprocessing import normalize\n",
    "from module_preprocessing import apply_preprocessing\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from time import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset violations loaded. Shape:  (8388, 2)\n",
      "dataset test20 loaded. Shape:  (3125, 2)\n",
      "dataset violations + train created. Shape:  (11513, 2)\n"
     ]
    }
   ],
   "source": [
    "data_violations = pd.read_csv(\n",
    "    \"crystal_ball_data/SIMPLE_PREP/all_violations_simple_rd.csv\",\n",
    "    index_col=\"index\")\n",
    "data_violations.raw_text = data_violations.raw_text.apply(literal_eval)\n",
    "print(\"dataset violations loaded. Shape: \", data_violations.shape)\n",
    "\n",
    "data_all_train = pd.read_csv(\n",
    "    \"crystal_ball_data/SIMPLE_PREP/all_train_simple_rd.csv\", index_col=\"index\")\n",
    "data_all_train.raw_text = data_all_train.raw_text.apply(literal_eval)\n",
    "print(\"dataset test20 loaded. Shape: \", data_all_train.shape)\n",
    "\n",
    "data_vt = data_violations.append(data_all_train)\n",
    "print(\"dataset violations + train created. Shape: \", data_vt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset Article02 has been loaded. Shape:  (26, 2)\n",
      "dataset Article03 has been loaded. Shape:  (140, 2)\n",
      "dataset Article05 has been loaded. Shape:  (74, 2)\n",
      "dataset Article06 has been loaded. Shape:  (226, 2)\n",
      "dataset Article08 has been loaded. Shape:  (111, 2)\n",
      "dataset Article10 has been loaded. Shape:  (52, 2)\n",
      "dataset Article11 has been loaded. Shape:  (14, 2)\n",
      "dataset Article13 has been loaded. Shape:  (52, 2)\n",
      "dataset Article14 has been loaded. Shape:  (70, 2)\n"
     ]
    }
   ],
   "source": [
    "path = \"crystal_ball_data/SIMPLE_PREP/test_RAW_DATASET/\"\n",
    "datasets = []\n",
    "for filename in os.listdir(path)[1:]:\n",
    "    dataset = pd.read_csv(path + filename, index_col=\"index\")\n",
    "    dataset.raw_text = dataset.raw_text.apply(literal_eval)\n",
    "    random.seed(6789)\n",
    "    dataset = dataset.sample(frac=1, random_state=6789).reset_index(drop=True)\n",
    "    print(\"dataset \" + filename[:9] + \" has been loaded. Shape: \",dataset.shape)\n",
    "    datasets.append([dataset, filename[:9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(df_test, model_D2V, verbose=0):\n",
    "    '''\n",
    "     Given a text, this function creates the vector through the Doc2Vec model and calculates \n",
    "     the class of the most similar text contained in the model. \n",
    "     In the end it calculates the accuracy.  \n",
    "      Args:\n",
    "        pandas.DataFrame, dataframe\n",
    "        gensim.models.doc2vec.Doc2Vec, Doc2Vec model\n",
    "        int, verbose\n",
    "      Returns :\n",
    "        float, accuracy\n",
    "         \n",
    "    '''\n",
    "    print(\"Testing applying 1-NN on\", len(df_test), \"samples\")\n",
    "    predictions = []\n",
    "    for index, row in df_test.iterrows():\n",
    "        vector = model_D2V.infer_vector(row['raw_text'])\n",
    "        most_similar = model_D2V.docvecs.most_similar([vector], topn=2)\n",
    "        predictions.append(most_similar[0][0][1])\n",
    "        #print(\"MOST SIMILAR to:\",index,most_similar[0],\"1st matches: \",row['tag']==most_similar[0][0][1],\" 2nd matches: \",row['tag']==most_similar[1][0][1],most_similar[1][1])\n",
    "        #print(data.iloc[most_similar[0][0][0]]['tag']==most_similar[0][0][1])\n",
    "        if verbose >= 2:\n",
    "            print(\"vector: \", vector)\n",
    "            print(\"tagged: \", most_similar[0][0], \"similarity: \",\n",
    "                  most_similar[1][1])\n",
    "    tag_test = df_test.loc[:, 'tag'].values\n",
    "    acc = metrics.accuracy_score(tag_test, predictions)\n",
    "    if verbose >= 0:\n",
    "        print(\"ACCURACY:\", acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total combination of parameters: 1\n",
      "\n",
      "parameters: {'dbow_words': 1, 'dm_mean': 1, 'epochs': 20, 'hs': 1, 'min_count': 1, 'negative': 5, 'ns_exponent': 1, 'vector_size': 100, 'window': 10}\n",
      "Article02\n",
      "Number of samples:  26\n",
      "Training the Doc2Vec with 12252 samples\n",
      "model Doc2Vec created. Time elasped: 0:26:03.231175\n",
      "Testing applying 1-NN on 26 samples\n",
      "ACCURACY: 0.7307692307692307\n",
      "Article03\n",
      "Number of samples:  140\n",
      "Training the Doc2Vec with 12138 samples\n",
      "model Doc2Vec created. Time elasped: 0:33:25.022874\n",
      "Testing applying 1-NN on 140 samples\n",
      "ACCURACY: 0.75\n",
      "Article05\n",
      "Number of samples:  74\n",
      "Training the Doc2Vec with 12204 samples\n",
      "model Doc2Vec created. Time elasped: 0:33:06.417797\n",
      "Testing applying 1-NN on 74 samples\n",
      "ACCURACY: 0.6621621621621622\n",
      "Article06\n",
      "Number of samples:  226\n",
      "Training the Doc2Vec with 12052 samples\n",
      "model Doc2Vec created. Time elasped: 0:29:00.850104\n",
      "Testing applying 1-NN on 226 samples\n",
      "ACCURACY: 0.672566371681416\n",
      "Article08\n",
      "Number of samples:  111\n",
      "Training the Doc2Vec with 12167 samples\n",
      "model Doc2Vec created. Time elasped: 0:24:15.897854\n",
      "Testing applying 1-NN on 111 samples\n",
      "ACCURACY: 0.7207207207207207\n",
      "Article10\n",
      "Number of samples:  52\n",
      "Training the Doc2Vec with 12226 samples\n",
      "model Doc2Vec created. Time elasped: 0:26:08.303464\n",
      "Testing applying 1-NN on 52 samples\n",
      "ACCURACY: 0.6538461538461539\n",
      "Article11\n",
      "Number of samples:  14\n",
      "Training the Doc2Vec with 12264 samples\n",
      "model Doc2Vec created. Time elasped: 0:21:02.735274\n",
      "Testing applying 1-NN on 14 samples\n",
      "ACCURACY: 0.6428571428571429\n",
      "Article13\n",
      "Number of samples:  52\n",
      "Training the Doc2Vec with 12226 samples\n",
      "model Doc2Vec created. Time elasped: 0:25:55.942650\n",
      "Testing applying 1-NN on 52 samples\n",
      "ACCURACY: 0.75\n",
      "Article14\n",
      "Number of samples:  70\n",
      "Training the Doc2Vec with 12208 samples\n",
      "model Doc2Vec created. Time elasped: 0:20:50.166813\n",
      "Testing applying 1-NN on 70 samples\n",
      "ACCURACY: 0.7428571428571429\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "summary = {}\n",
    "param_grid = {\n",
    "    'vector_size': [100],\n",
    "    'epochs': [20],\n",
    "    'min_count': [1],\n",
    "    'window': [10],\n",
    "    'hs': [1],\n",
    "    'negative': [5],\n",
    "    'ns_exponent': [1],\n",
    "    'dm_mean': [1],\n",
    "    'dbow_words': [1]\n",
    "}\n",
    "parameters = list(ParameterGrid(param_grid))\n",
    "print(\"\\nTotal combination of parameters: %d\" % len(parameters))\n",
    "for parameter in parameters:\n",
    "    print(\"\\nparameters:\", parameter)\n",
    "    l = []\n",
    "    for i, (dataset, filename) in enumerate(datasets):\n",
    "        print(filename)\n",
    "        print(\"Number of samples: \", dataset.shape[0])\n",
    "        data = data_vt\n",
    "        temp = datasets[:i] + datasets[i + 1:]\n",
    "        for d in temp:\n",
    "            data = data.append(d[0])\n",
    "        data = data.sample(frac=1, random_state=6789).reset_index(drop=True)\n",
    "        tagged_documents = []\n",
    "        for index, row in data.iterrows():\n",
    "            tagged_documents.append(\n",
    "                TaggedDocument(\n",
    "                    words=row['raw_text'], tags=[(index, row['tag'])]))\n",
    "        print(\"Training the Doc2Vec with\", len(data), \"samples\")\n",
    "        start = time()\n",
    "        model_D2V = Doc2Vec(\n",
    "            tagged_documents,\n",
    "            negative=parameter['negative'],\n",
    "            ns_exponent=parameter['ns_exponent'],\n",
    "            hs=parameter['hs'],\n",
    "            window=parameter['window'],\n",
    "            dm_mean=parameter['dm_mean'],\n",
    "            dm_concat=0,\n",
    "            dbow_words=parameter['dbow_words'],\n",
    "            vector_size=parameter['vector_size'],\n",
    "            epochs=parameter['epochs'],\n",
    "            min_count=parameter['min_count'],\n",
    "            workers=os.cpu_count())\n",
    "        print(\"model Doc2Vec created. Time elasped: \" +\n",
    "              str(timedelta(seconds=(time() - start))))\n",
    "        accuracy = fit(dataset, model_D2V, verbose=0)\n",
    "        l.append((filename, accuracy))\n",
    "    summary.update({str(parameter): l})\n",
    "\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:  {'dbow_words': 1, 'dm_mean': 1, 'epochs': 20, 'hs': 1, 'min_count': 1, 'negative': 5, 'ns_exponent': 1, 'vector_size': 100, 'window': 10}\n",
      "Article02 average: 0.730769\n",
      "Article03 average: 0.750000\n",
      "Article05 average: 0.662162\n",
      "Article06 average: 0.672566\n",
      "Article08 average: 0.720721\n",
      "Article10 average: 0.653846\n",
      "Article11 average: 0.642857\n",
      "Article13 average: 0.750000\n",
      "Article14 average: 0.742857\n",
      "Total average: 0.702864\n"
     ]
    }
   ],
   "source": [
    "for i in summary:\n",
    "    print(\"\\nParameters: \", i)\n",
    "    total_average = 0\n",
    "    for j in range(len(summary[i])):\n",
    "        print(summary[i][j][0], \"average: %f\" % summary[i][j][1])\n",
    "        total_average += summary[i][j][1]\n",
    "    total_average = total_average / len(summary[i])\n",
    "    print(\"Total average: %f\" % total_average)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:  {'dbow_words': 0, 'dm_mean': 0, 'epochs': 20, 'hs': 0, 'min_count': 1, 'negative': 5, 'ns_exponent': 1, 'vector_size': 500, 'window': 3}\n",
      "Article02 average: 0.653846\n",
      "Article03 average: 0.742857\n",
      "Article05 average: 0.662162\n",
      "Article06 average: 0.663717\n",
      "Article08 average: 0.720721\n",
      "Article10 average: 0.673077\n",
      "Article11 average: 0.714286\n",
      "Article13 average: 0.769231\n",
      "Article14 average: 0.728571\n",
      "Total average: 0.703163\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:  {'dbow_words': 1, 'dm_mean': 1, 'epochs': 20, 'hs': 1, 'min_count': 1, 'negative': 20, 'ns_exponent': 1, 'vector_size': 100, 'window': 3}\n",
      "Article02 average: 0.653846\n",
      "Article03 average: 0.735714\n",
      "Article05 average: 0.675676\n",
      "Article06 average: 0.663717\n",
      "Article08 average: 0.702703\n",
      "Article10 average: 0.750000\n",
      "Article11 average: 0.642857\n",
      "Article13 average: 0.788462\n",
      "Article14 average: 0.714286\n",
      "Total average: 0.703029\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "386px",
    "left": "819px",
    "right": "20px",
    "top": "82px",
    "width": "505px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
